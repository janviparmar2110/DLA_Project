import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split

import pandas as pd
import random

# Define emotions and example templates
emotions = ['happy', 'sad', 'angry', 'fear', 'surprise', 'calm']

emotion_sentences = {
    'happy': [
        "I am feeling very happy today!",
        "This is the best day of my life!",
        "I am so excited about the new job!",
        "Life is beautiful and full of joy.",
        "Everything is going perfectly fine.",
        "I can’t stop smiling all day.",
        "I’m grateful for everything I have.",
        "I feel blessed and cheerful.",
        "My heart is full of happiness.",
        "That song made my day so much better!"
    ],
    'sad': [
        "I feel so lonely and down.",
        "Nothing seems to make sense anymore.",
        "I am heartbroken after what happened.",
        "Tears keep falling from my eyes.",
        "I miss my friends so much.",
        "I am upset because I failed the test.",
        "Life feels dull and meaningless.",
        "Everything around me feels grey.",
        "I just want to be alone for a while.",
        "Today has been a really rough day."
    ],
    'angry': [
        "I am furious right now!",
        "They really made me mad today.",
        "I can’t believe how rude they were.",
        "I’m losing my temper over this.",
        "Everything is making me angry lately.",
        "Why can’t people just be respectful?",
        "I hate being lied to.",
        "That really crossed the line!",
        "I feel so frustrated right now.",
        "My patience is running out."
    ],
    'fear': [
        "I’m scared of what might happen next.",
        "That noise gave me chills.",
        "I can’t go in there, it’s too dark.",
        "I feel nervous about tomorrow.",
        "This place gives me the creeps.",
        "I’m terrified of losing my loved ones.",
        "That horror movie was terrifying.",
        "I’m worried something bad will happen.",
        "I’m shivering with fear.",
        "I feel so unsafe here."
    ],
    'surprise': [
        "Wow, I didn’t expect that!",
        "That’s unbelievable!",
        "Oh my god, really?",
        "What a pleasant surprise!",
        "I can’t believe this just happened.",
        "That news came out of nowhere!",
        "I never thought I’d see this day.",
        "You’ve got to be kidding me!",
        "This is totally unexpected.",
        "That gift completely surprised me!"
    ],
    'calm': [
        "I feel peaceful and relaxed.",
        "Everything is calm and quiet.",
        "I’m content with how things are going.",
        "My mind feels at ease.",
        "I’m enjoying the silence.",
        "I feel balanced and stable.",
        "Life feels simple and serene.",
        "I’m just breathing and being.",
        "Everything is under control.",
        "I’m calm and composed."
    ]
}

# Generate a large dataset (300 samples total)
texts = []
labels = []

for emotion in emotions:
    for _ in range(50):  # 50 samples per emotion
        sentence = random.choice(emotion_sentences[emotion])
        texts.append(sentence)
        labels.append(emotion)

# Create DataFrame
df = pd.DataFrame({'text': texts, 'emotion': labels})

# Shuffle the dataset
df = df.sample(frac=1).reset_index(drop=True)

# Save to CSV
df.to_csv('emotion_dataset.csv', index=False)

print("✅ emotion_dataset.csv created successfully with", len(df), "rows")
print(df.head(10))


# Load dataset
data = pd.read_csv("emotion_dataset.csv")

print(data.head())


# Download stopwords
nltk.download('stopwords')
nltk.download('punkt')
nltk.download('punkt_tab')

stop_words = set(stopwords.words('english'))

# Text cleaning function
def clean_text(text):
    tokens = word_tokenize(text.lower())
    tokens = [word for word in tokens if word.isalpha() and word not in stop_words]
    return ' '.join(tokens)

data['clean_text'] = data['text'].apply(clean_text)
tokenizer = Tokenizer(num_words=5000, oov_token="<OOV>")
tokenizer.fit_on_texts(data['clean_text'])

X = tokenizer.texts_to_sequences(data['clean_text'])
X = pad_sequences(X, maxlen=50, padding='post', truncating='post')

label_encoder = LabelEncoder()
y = label_encoder.fit_transform(data['emotion'])

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
model = Sequential([
    Embedding(input_dim=5000, output_dim=64, input_length=50),
    LSTM(128, return_sequences=False),
    Dropout(0.3),
    Dense(64, activation='relu'),
    Dropout(0.3),
    Dense(len(np.unique(y)), activation='softmax')
])

model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
model.summary()
history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), batch_size=32)
loss, accuracy = model.evaluate(X_test, y_test)
print(f"Test Accuracy: {accuracy:.2f}")
plt.plot(history.history['accuracy'], label='train acc')
plt.plot(history.history['val_accuracy'], label='val acc')
plt.legend()
plt.title("Accuracy Over Epochs")
plt.show()
def predict_emotion(text):
    seq = tokenizer.texts_to_sequences([clean_text(text)])
    pad = pad_sequences(seq, maxlen=50)
    pred = model.predict(pad)
    emotion = label_encoder.inverse_transform([np.argmax(pred)])
    return emotion[0]

print(predict_emotion("I am feeling awesome today!"))
print(predict_emotion("I am so scared right now."))
